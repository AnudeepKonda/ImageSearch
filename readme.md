# Image Search Engine

## Overview

The Image Search Engine is a modular and scalable application designed to index and search images using embeddings generated by OpenAI's CLIP model. It supports querying with both images and text, offering high performance and flexibility through its FastAPI backend and ChromaDB vector storage.

### Design Decisions

1. **Technology Choices**:
   - **Programming Language**: Python was chosen for its rich ecosystem of libraries for machine learning and web development.
   - **Vector Database**: ChromaDB was selected for its high-performance vector search capabilities, ability to support multiple indexes and similarity metrics, and capacity to scale with millions of data points. It offers efficient key deletion without needing a full index rebuild, enhancing operational flexibility. Additionally, its server/client mode supports distributed systems, while async operations ensure improved performance and responsiveness under heavy loads.
   - **Embeddings**: The image and text embeddings are generated using OpenAI's CLIP, a robust model known for its ability to semantically encode both text and images into the same latent space. This approach simplifies the search process by enabling relevance determination through a straightforward dot product, ensuring efficient and accurate similarity matching across multimodal data.
   - **Similarity Metric**: Since CLIP embeddings are normalized, cosine similarity is the most appropriate metric for measuring similarity. It effectively captures the angular distance between embeddings, making it ideal for evaluating the closeness of text and image representations in the shared latent space.

   Retrieval is done only on embeddings, no metadata or tags are used.

2. **Scalability**:
   - ChromaDB runs in server mode, enabling multi-tenant concurrent CRUD operations.
   - The embedding server and search engine are decoupled, allowing independent scaling of components.

3. **Maintainability**:
   - Modular design separates concerns (e.g., embedding generation, database interaction, API endpoints).
   - Comprehensive error handling and validation ensure robustness.
   - Clear documentation and type annotations improve code readability.

4. **Performance Optimization**:
   - Embeddings are computed asynchronously to handle high-concurrency scenarios, using a FastAPI server. 
   - Vector search is optimized using HNSW (Hierarchical Navigable Small World) for efficient nearest-neighbor queries, utilizing cosine similarity to measure similarity.


## Setup Instructions

Ensure you have Python 3.10 or later installed, then install the required dependencies:

```bash
pip install -r requirements.txt
```

1. Start ChromaDB:
   ```bash
   chroma run --port 9000
   ```

2. Start the embedding server:
   ```bash
   uvicorn embedding_server:app --host 0.0.0.0 --port 8000 --reload
   ```

You can now create an instance of the `image_search_engine.ImageSearchEngine` class to seamlessly interact with the ChromaDB server. Refer to the `visualization.ipynb` for more details.


## API Documentation

### Base URLs

- Embedding Server: `http://localhost:8000`
- Chroma DB Server: `http://localhost:9000`


### Embedding Server

1. **Text Embedding**
   - **Endpoint**: `/embed_text`
   - **Method**: POST
   - **Payload**:
     ```json
     {
       "query": "Description of the image content to search for similar images"
     }
     ```
   - **Response**:
     ```json
     {
       "embedding": [0.1, 0.2, ...]  // 512-dimensional vector
     }
     ```

2. **Image Embedding**
   - **Endpoint**: `/embed_image`
   - **Method**: POST
   - **Payload**:
     ```json
     {
       "image_url": "https://example.com/image.jpg"
     }
     ```
   - **Response**:
     ```json
     {
       "embedding": [0.1, 0.2, ...]  // 512-dimensional vector
     }
     ```

### Image Search Engine

1. **Index Image**
    - **Method**: `index_image`
    - **Description**: Adds an image to the ChromaDB index using its URL and optional metadata.
    - **Parameters**:
      ```python
      image_url: str  # URL of the image to index
      metadata: dict = None  # Optional metadata (e.g., category, tags)
      ```
    - **Example**:
      ```python
      engine.index_image(
            image_url="https://example.com/image.jpg",
            metadata={"category": "nature", "tags": ["forest", "trees"]}
      )
      ```
    - **Response**: Raises an exception if the image is already indexed or if indexing fails.

2. **Remove Image**
    - **Method**: `remove_image_from_index`
    - **Description**: Removes an image from the ChromaDB index using its URL.
    - **Parameters**:
      ```python
      image_url: str  # URL of the image to remove
      ```
    - **Example**:
      ```python
      engine.remove_image_from_index(image_url="https://example.com/image.jpg")
      ```
    - **Response**: Raises an exception if the image is not found or if removal fails.

3. **Search by Text**
    - **Method**: `search_text`
    - **Description**: Searches for relevant images in the index using a text query.
    - **Parameters**:
      ```python
      query_text: str  # Text description of the image
      top_k: int = 5  # Number of top results to return
      ```
    - **Example**:
      ```python
      urls, distances = engine.search_text(query_text="A description of the image", top_k=5)
      ```
    - **Response**:
      - `urls`: List of image URLs.
      - `distances`: List of similarity scores.

4. **Search by Image**
    - **Method**: `search_image`
    - **Description**: Searches for visually similar images in the index using an image URL.
    - **Parameters**:
      ```python
      query_image_url: str  # URL of the query image
      top_k: int = 5  # Number of top results to return
      ```
    - **Example**:
      ```python
      urls, distances = engine.search_image(query_image_url="https://example.com/image.jpg", top_k=5)
      ```
    - **Response**:
      - `urls`: List of image URLs.
      - `distances`: List of similarity scores.
     


## Testing
Test coverage includes:
   - Indexing single and multiple images.
   - Searching by text and image.
   - Handling duplicate indexing and deletion.
   - Persistence of the database.

   ```bash
   python test.py
   ```


## Future Improvements

1. **Search Quality**:
   - Implement advanced ranking strategies, such as using weighted embeddings to prioritize specific features or attributes.
   - Fine-tune the CLIP model for domain-specific tasks to improve embedding relevance and search accuracy.
   - Leverage hybrid search by combining embeddings with available image tags for enhanced retrieval.
      - Synthesize image tags automatically during indexing to enrich metadata and improve search results.
    
2. **Performance**:
   - Enable support for batch processing when generating embeddings from the CLIP model.
   - Introduce parallel processing for large-scale indexing and search operations.

3. **Scalability**:
   - Deploy the system on a cloud platform with auto-scaling.

4. **User Experience**:
   - Add a frontend for visualizing search results.
   - Provide batch indexing and search capabilities.


## Demo

The provided `visualization.ipynb` serves as a live demo showcasing the capabilities of the Image Search Engine. It includes the following:

1. **Loading and Displaying Images**:
    - Demonstrates how to fetch and visualize a set of images from a remote repository.

2. **Indexing Images**:
    - Illustrates the process of adding images to the ChromaDB index using the `ImageSearchEngine` class.

3. **Text-Based Search**:
    - Shows how to retrieve relevant images based on text queries, leveraging the embeddings generated by OpenAI's CLIP model.
    - Example queries include descriptions like "hedgehog" or "city lights," with results displayed in order of relevance.

4. **Image-Based Search**:
    - Highlights the ability to find visually similar images using a query image.
    - The notebook demonstrates the retrieval of top matches, ranked by cosine similarity.

To explore the demo:
- Open the `visualization.ipynb` notebook in Jupyter or any compatible environment.
- Follow the step-by-step code cells to interact with the Image Search Engine and visualize the results.

This hands-on demo provides a comprehensive overview of the system's functionality and performance.